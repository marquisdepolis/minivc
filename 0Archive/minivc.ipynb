{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://consensus.app/search', 'https://consensus.app/home/blog/category/news/', 'https://consensus.app/sign-in/', 'https://consensus.app/results/?q=Does creatine help build muscle?', 'https://consensus.app/sign-up', 'https://consensus.app/home/blog/welcome-to-consensus/', 'https://consensus.app/home/blog/', 'https://consensus.app/home', 'https://consensus.app/home/', 'https://consensus.app/sign-up/', 'https://consensus.app/results/?q=Do direct cash transfers reduce poverty?', 'https://consensus.app/home/contact-us/', 'https://consensus.app/sitemap.xml', 'https://consensus.app/blog/maximize-your-consensus-experience-with-these-best-practices/', 'https://consensus.app/results/?q=Can mindfulness improve sleep?', 'https://consensus.app/home/about-us/'}\n",
      "5\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, your messages resulted in 166097 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 269\u001b[0m\n\u001b[1;32m    266\u001b[0m         url \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     analyze_input(input_type, company, url)\n\u001b[0;32m--> 269\u001b[0m run()\n",
      "Cell \u001b[0;32mIn[6], line 267\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m analyze_input(input_type, company, url)\n",
      "Cell \u001b[0;32mIn[6], line 216\u001b[0m, in \u001b[0;36manalyze_input\u001b[0;34m(input_type, company, url)\u001b[0m\n\u001b[1;32m    214\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m input_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 216\u001b[0m     data \u001b[39m=\u001b[39m link(url)\n\u001b[1;32m    217\u001b[0m \u001b[39melif\u001b[39;00m input_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mpdf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpptx\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    218\u001b[0m     file_path \u001b[39m=\u001b[39m get_file_input(input_type)\n",
      "Cell \u001b[0;32mIn[6], line 186\u001b[0m, in \u001b[0;36mlink\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    184\u001b[0m full_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(all_text)\n\u001b[1;32m    185\u001b[0m full_text \u001b[39m=\u001b[39m clean_text(full_text)\n\u001b[0;32m--> 186\u001b[0m analyzed_data \u001b[39m=\u001b[39m recursive_analyze(full_text)\n\u001b[1;32m    187\u001b[0m \u001b[39mreturn\u001b[39;00m analyzed_data\n",
      "Cell \u001b[0;32mIn[6], line 159\u001b[0m, in \u001b[0;36mrecursive_analyze\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    157\u001b[0m insights_data \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(text_chunks):\n\u001b[0;32m--> 159\u001b[0m     insights_list \u001b[39m=\u001b[39m call_gpt(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mExtract all insights and facts from the following text as bullet points which would be useful for an investment memo:\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mchunk\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    160\u001b[0m     \u001b[39mfor\u001b[39;00m category \u001b[39min\u001b[39;00m categories:\n\u001b[1;32m    161\u001b[0m         explanation \u001b[39m=\u001b[39m category_explanation_map[category]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 121\u001b[0m, in \u001b[0;36mcall_gpt\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    119\u001b[0m textchunks \u001b[39m=\u001b[39m split_text(prompt)\n\u001b[1;32m    120\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m textchunks:\n\u001b[0;32m--> 121\u001b[0m     answer \u001b[39m=\u001b[39m base_gptcall(chunk)\n\u001b[1;32m    122\u001b[0m     answers\u001b[39m.\u001b[39mappend(answer)\n\u001b[1;32m    123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(answers)\n",
      "Cell \u001b[0;32mIn[6], line 108\u001b[0m, in \u001b[0;36mbase_gptcall\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbase_gptcall\u001b[39m(prompt):\n\u001b[1;32m    107\u001b[0m     messages \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt}]\n\u001b[0;32m--> 108\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    109\u001b[0m         model\u001b[39m=\u001b[39;49mMODEL,\n\u001b[1;32m    110\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m    111\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, your messages resulted in 166097 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import openai\n",
    "import PyPDF2\n",
    "import requests\n",
    "import tldextract\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from pptx import Presentation\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from tkinter import Tk, filedialog\n",
    "import readppt\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "MODEL = \"gpt-4\"\n",
    "CHUNK_SIZE=7500\n",
    "ALLOWED_TLDS = {\"com\", \"app\",\"org\", \"net\", \"edu\", \"gov\"}\n",
    "EXCLUDED_KEYWORDS = {\n",
    "    \"login\",\n",
    "    \"signup\",\n",
    "    \"register\",\n",
    "    \"account\",\n",
    "    \"privacy\",\n",
    "    \"terms\",\n",
    "    \"policy\",\n",
    "    \"disclaimer\",\n",
    "    \"jobs\",\n",
    "    \"careers\",\n",
    "    \"blog\"\n",
    "    \"contact\",\n",
    "    \"cookie\",\n",
    "    \"support\",\n",
    "    \"forum\",\n",
    "    \"cdn\",\n",
    "    \"newsletter\",\n",
    "    \"status\",\n",
    "}\n",
    "FILENAME = \"analyzed_data.json\"\n",
    "\n",
    "def get_links(soup, base_url):\n",
    "    links = set()\n",
    "\n",
    "    parsed_base_url = urlparse(base_url)\n",
    "    ext = tldextract.extract(parsed_base_url.netloc)\n",
    "    base_domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "    allowed_domains = {base_domain}\n",
    "\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"]\n",
    "        if not href.startswith(\"http\"):\n",
    "            href = urljoin(base_url, href)\n",
    "        \n",
    "        parsed_url = urlparse(href)\n",
    "        ext = tldextract.extract(parsed_url.netloc)\n",
    "        domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "\n",
    "        if (base_url in href\n",
    "            and domain in allowed_domains\n",
    "            and ext.suffix in ALLOWED_TLDS\n",
    "            and not any(keyword in href.lower() for keyword in EXCLUDED_KEYWORDS)\n",
    "        ):\n",
    "            links.add(href)\n",
    "    print(links)\n",
    "    return links\n",
    "\n",
    "def fetch_html(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {url}\\n{str(e)}\")\n",
    "        return None\n",
    "    return soup\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = \" \".join(text.split())\n",
    "    cleaned_text = cleaned_text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9.,!?/:;()%$@&\\s]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(\n",
    "        r'(?i)(terms\\s*and\\s*conditions|privacy\\s*policy|copyright|blog|legal|careers|cdn*).{0,10}', '', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def split_text(text, chunk_size=CHUNK_SIZE):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    for word in words:\n",
    "        if len(\" \".join(current_chunk) + \" \" + word) <= chunk_size:\n",
    "            current_chunk.append(word)\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "def base_gptcall(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return response.choices[0]['message']['content'].strip()\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=2, max=20), stop=stop_after_attempt(3), reraise=True)\n",
    "def call_gpt(prompt):\n",
    "    answers = []\n",
    "    if len(prompt)>CHUNK_SIZE:\n",
    "        textchunks = split_text(prompt)\n",
    "        for chunk in textchunks:\n",
    "            answer = base_gptcall(chunk)\n",
    "            answers.append(answer)\n",
    "        return ' '.join(answers)\n",
    "    else:\n",
    "        return base_gptcall(prompt)\n",
    "\n",
    "def recursive_analyze(text):\n",
    "    categories = [\n",
    "        \"Team\",\n",
    "        \"Customers\",\n",
    "        \"Product\",\n",
    "        \"Market\",\n",
    "        \"Business Model\",\n",
    "        \"Risks\",\n",
    "        \"Traction\"\n",
    "    ]\n",
    "    category_explanation = [\n",
    "        \"\"\"The team section should focus on the co-founders' names, backgrounds, experiences, and the expertise of key advisors or partners, avoiding discussions about the product or competition.\n",
    "        Example: Co-founders Patrick Collison (ex-CEO of Auctomatic) and John Collison (ex-CTO of Auctomatic) lead Stripe, which has attracted top talent from companies like Google and Apple.\"\"\",\n",
    "        \"\"\"The customers section should concentrate on target customer segments, industries, specific companies, and notable partnerships, without repeating information about product features or benefits.\n",
    "        Example: Stripe serves businesses of all sizes across various industries, from startups like Instacart to tech giants like Amazon, providing seamless payment solutions.\"\"\",\n",
    "        \"\"\"The product section should describe the main product(s) or service(s), highlighting key features, benefits, use cases, and unique selling points, without discussing market size or competition.\n",
    "        Example: Stripe offers a suite of payment processing services, including Stripe Payments for online transactions, Stripe Billing for subscription management, and Stripe Connect for marketplace platforms.\"\"\",\n",
    "        \"\"\"The market section should assess the market size, growth potential, and any adjacent opportunities, without reiterating information about the product, customers, or competition.\n",
    "        Example: Stripe operates in the global digital payments market, valued at over $4 trillion, with significant growth opportunities as e-commerce and digital transactions continue to rise.\"\"\",\n",
    "        \"\"\"The business model section should explain the startup's revenue generation methods and pricing strategies, without focusing on product features or competition.\n",
    "        Example: Stripe employs a pay-as-you-go pricing model, charging a percentage of each transaction, and offers additional features through tiered pricing plans and custom enterprise solutions.\"\"\",\n",
    "        \"\"\"The risks section should identify potential internal and external risks that could impact the investment, avoiding repetition of product features, benefits, or market size.\n",
    "        Example: Stripe faces competition from companies like PayPal and Square, potential regulatory changes affecting the fintech industry, and evolving cyber threats and security concerns.\"\"\",\n",
    "        \"\"\"The traction section should cover growth rates, user engagement metrics, milestones, and future goals, without discussing the product, competition, or market size.\n",
    "        Example: Stripe has experienced rapid growth, with millions of businesses using its platform, raising over $1.6 billion in funding, and expanding its services to over 40 countries.\"\"\"\n",
    "    ]\n",
    "\n",
    "    category_explanation_map = dict(zip(categories, category_explanation))\n",
    "    text_chunks = split_text(text)\n",
    "    print(len(text_chunks))\n",
    "    insights_data = defaultdict(list)\n",
    "    for chunk in enumerate(text_chunks):\n",
    "        insights = call_gpt(f\"Extract all insights and facts from the following text as bullet points which would be useful for an investment memo:\\n\\n{chunk}\")\n",
    "        for category in categories:\n",
    "            explanation = category_explanation_map[category]\n",
    "            prompt = f\"Imagining you to be writing a VC investment memo, from the following text please extract information regarding the category '{category}'. An example is here: {explanation}. If no useful information is present, please reply with 'info not available':\\n\\n{insights}\"\n",
    "            summary = call_gpt(prompt)                    \n",
    "            insights_data[category].append(summary)\n",
    "\n",
    "    return insights_data\n",
    "\n",
    "def link(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    if not parsed_url.scheme or not parsed_url.hostname:\n",
    "        print(\"Invalid URL. Please provide a valid URL with a scheme (e.g., http:// or https://).\")\n",
    "        return None\n",
    "    base_url = parsed_url.scheme + \"://\" + parsed_url.hostname\n",
    "    soup = fetch_html(url)\n",
    "    if not soup:\n",
    "        return None\n",
    "    links = get_links(soup, base_url)\n",
    "    all_text = []\n",
    "    for link in links:\n",
    "        sub_soup = fetch_html(link)\n",
    "        if sub_soup:\n",
    "            text = clean_text(sub_soup.get_text())\n",
    "            all_text.append(text)\n",
    "    full_text = \" \".join(all_text)\n",
    "    full_text = clean_text(full_text)\n",
    "    analyzed_data = recursive_analyze(full_text)\n",
    "    return analyzed_data\n",
    "\n",
    "def read_pdf(file):\n",
    "    file.seek(0)  # move the file cursor to the beginning\n",
    "    pdf_reader = PyPDF2.PdfReader(file)\n",
    "    if len(pdf_reader.pages) == 0:\n",
    "        raise ValueError(\"PDF file is empty\")\n",
    "    text = \"\"\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        text += pdf_reader.pages[page_num].extract_text()\n",
    "    cleaned_text = clean_text(text)\n",
    "    return cleaned_text\n",
    "\n",
    "def get_file_input(input_type):\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    if input_type == \"pdf\":\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "    elif input_type == \"pptx\":\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"PowerPoint files\", \"*.pptx\")])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input type\")\n",
    "\n",
    "    return file_path\n",
    "\n",
    "def analyze_input(input_type, company, url):\n",
    "    text = \"\"\n",
    "    if input_type == \"url\":\n",
    "        data = link(url)\n",
    "    elif input_type in [\"pdf\", \"pptx\"]:\n",
    "        file_path = get_file_input(input_type)\n",
    "        if not file_path:\n",
    "            print(\"No file selected.\")\n",
    "            return\n",
    "\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            if input_type == \"pdf\":\n",
    "                text = read_pdf(file)\n",
    "            elif input_type == \"pptx\":\n",
    "                file_content = file.read()\n",
    "                text = readppt.read_ppt(file_content)\n",
    "        data = recursive_analyze(text)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input type\")\n",
    "    \n",
    "    company_data = []\n",
    "    for category, summary in data.items():\n",
    "        edited_summary = call_gpt(f\"Please rewrite this summary:{summary}\")\n",
    "        print(f\"{category}:\\n{edited_summary}\\n\")\n",
    "        data_to_save = {\n",
    "            \"category\": category,\n",
    "            \"edited_summary\": edited_summary\n",
    "        }\n",
    "        company_data.append(data_to_save)\n",
    "    \n",
    "    save_data(FILENAME, company, company_data)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def save_data(filename, company, data):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    if not os.path.exists(filename):\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump({}, f)\n",
    "    with open(filename, \"r\") as f:\n",
    "        all_data = json.load(f)\n",
    "    if company not in all_data:\n",
    "        all_data[company] = {}\n",
    "    all_data[company][timestamp] = data\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(all_data, f, indent=4)\n",
    "\n",
    "def run():\n",
    "    input_type = input(\"Enter the input type (URL/PDF/PPTX): \").lower()\n",
    "    company = input(\"Enter company name: \")\n",
    "    if input_type == \"url\":\n",
    "        url = input(\"Enter a URL: \")\n",
    "    else:\n",
    "        url = None\n",
    "    analyze_input(input_type, company, url)\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
